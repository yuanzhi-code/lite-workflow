import asyncio
import os
import sys
import time

# ç¡®ä¿èƒ½å¯¼å…¥ lite_workflow æ¨¡å—
sys.path.insert(
    0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "src"))
)

from lite_workflow.components.chat_models import ChatSiliconFlow, Message
from lite_workflow.core.error_handler import ErrorHandler, ErrorPolicy
from lite_workflow.core.state_manager import StateManager
from lite_workflow.definitions.edge import Edge
from lite_workflow.definitions.graph import Graph
from lite_workflow.definitions.node import create_function_node
from lite_workflow.engine.pregel_engine import PregelEngine

# èŠ‚ç‚¹å®ç°


def initial_prompt_node(inputs: dict) -> dict:
    """å¤„ç†åˆå§‹è¾“å…¥å¹¶å‡†å¤‡å¥½è¿›è¡Œå¤§æ¨¡å‹è°ƒç”¨ã€‚"""
    prompt = inputs.get("prompt", "è¯·ç”¨ä¸­æ–‡ç®€æ´ä»‹ç»ä¸€ä¸‹æœºå™¨å­¦ä¹ ã€‚")
    print(f"ğŸ“ [å¼€å§‹] æ¥æ”¶åˆ°æç¤º: {prompt}")
    return {"prompt": prompt}


async def silicon_flow_chat_node(inputs: dict) -> dict:
    """è°ƒç”¨ç¡…åŸºæµåŠ¨æ¨¡å‹ç”Ÿæˆå›å¤ã€‚"""
    user_prompt = inputs.get("prompt", "")
    print(f"ğŸ’¬ [ç¡…åŸºæµåŠ¨] è¾“å…¥: {user_prompt}")
    if not user_prompt:
        return {"error": "æœªæä¾›ç”¨æˆ·æç¤º", "model_response": ""}

    # æ£€æŸ¥ API KEY
    api_key = os.environ.get("SILICONFLOW_API_KEY")
    if not api_key:
        print("âŒ [ç¡…åŸºæµåŠ¨] æœªè®¾ç½® SILICONFLOW_API_KEY ç¯å¢ƒå˜é‡")
        return {"error": "æœªè®¾ç½® SILICONFLOW_API_KEY ç¯å¢ƒå˜é‡", "model_response": ""}

    print(f"ğŸ”‘ [ç¡…åŸºæµåŠ¨] API KEY å·²è®¾ç½®: {api_key[:10]}...")

    try:
        print("ğŸš€ [ç¡…åŸºæµåŠ¨] æ­£åœ¨åˆ›å»ºæ¨¡å‹å®ä¾‹...")
        model = ChatSiliconFlow(model="Qwen/Qwen3-8B", api_key=api_key)
        print("âœ… [ç¡…åŸºæµåŠ¨] æ¨¡å‹å®ä¾‹åˆ›å»ºæˆåŠŸ")

        print("ğŸ“¤ [ç¡…åŸºæµåŠ¨] æ­£åœ¨è°ƒç”¨æ¨¡å‹...")
        messages = [Message.user(user_prompt)]
        result = await model.ainvoke(messages)
        model_response = result.content
        print(f"âœ¨ [ç¡…åŸºæµåŠ¨] æ¨¡å‹å›å¤: {model_response[:100]}...")
        return {"model_response": model_response, "original_prompt": user_prompt}
    except Exception as e:
        print(f"âŒ [ç¡…åŸºæµåŠ¨] æ¨¡å‹è°ƒç”¨å¤±è´¥: {e}")
        print(f"âŒ [ç¡…åŸºæµåŠ¨] é”™è¯¯ç±»å‹: {type(e).__name__}")
        import traceback

        print(f"âŒ [ç¡…åŸºæµåŠ¨] é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
        return {"error": str(e), "model_response": ""}


def final_output_node(inputs: dict) -> dict:
    """æ•´ç†å¹¶è¾“å‡ºæœ€ç»ˆç»“æœã€‚"""
    original_prompt = inputs.get("original_prompt", "æ— ")
    model_response = inputs.get("model_response", "æ— å›å¤")
    error = inputs.get("error", None)

    print("ğŸ‰ [å®Œæˆ] æœ€ç»ˆç»“æœï¼š")
    print(f"   åŸå§‹æç¤º: {original_prompt}")
    if error:
        print(f"   é”™è¯¯ä¿¡æ¯: {error}")
    print(f"   æ¨¡å‹å›å¤: {model_response}")

    return {
        "final_output": {
            "original_prompt": original_prompt,
            "model_response": model_response,
            "error": error,
        }
    }


# å›¾ç»“æ„æ„å»ºå™¨


def create_siliconflow_graph() -> Graph:
    """åˆ›å»ºåŒ…å«ç¡…åŸºæµåŠ¨è°ƒç”¨çš„å›¾ç»“æ„ã€‚"""
    nodes = [
        create_function_node("initial_prompt", initial_prompt_node),
        create_function_node("silicon_flow_chat", silicon_flow_chat_node),
        create_function_node("final_output", final_output_node),
    ]
    edges = [
        Edge("initial_prompt", "silicon_flow_chat"),
        Edge("silicon_flow_chat", "final_output"),
    ]
    return Graph("siliconflow_chat_demo", nodes, edges, "initial_prompt")


# æ‰§è¡Œå‡½æ•°


async def run_siliconflow_demo():
    """è¿è¡Œç¡…åŸºæµåŠ¨å›¾ç¼–æ’æµ‹è¯•ã€‚"""
    print("ğŸ¯ ç¡…åŸºæµåŠ¨èŠå¤©å›¾ç¼–æ’æµ‹è¯•")
    print("=" * 60)

    graph = create_siliconflow_graph()
    print(f"ğŸ“Š å›¾å·²æ„å»º: {len(graph.nodes)} èŠ‚ç‚¹, {len(graph.edges)} è¾¹")
    print(f"   èµ·å§‹èŠ‚ç‚¹: {graph.start_node}")
    print(f"   ç»ˆæ­¢èŠ‚ç‚¹: {[n for n in graph.nodes if graph.is_terminal(n)]}")

    print(f"âœ… å›¾éªŒè¯: {graph.validate_cycles()}")

    initial_state = {"prompt": "è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ã€‚"}
    state_manager = StateManager(initial_state)
    error_handler = ErrorHandler()

    # è®¾ç½®é”™è¯¯å¤„ç†ç­–ç•¥ä¸ºå¿«é€Ÿå¤±è´¥ï¼Œè¿™æ ·å¯ä»¥çœ‹åˆ°å…·ä½“é”™è¯¯
    error_handler.default_policy = ErrorPolicy.FAIL_FAST
    engine = PregelEngine(graph, state_manager, error_handler)

    print("\nğŸ”„ å¼€å§‹æ‰§è¡Œ...")
    print(f"åˆå§‹çŠ¶æ€: {initial_state}")

    start_time = time.time()
    final_state = await engine.execute_async()
    execution_time = time.time() - start_time

    print("\nğŸ‰ æ‰§è¡Œå®Œæˆ!")
    print(f"æ€»è€—æ—¶: {execution_time:.2f}s")

    final_data = final_state.to_dict()
    print("\nğŸ“‹ æœ€ç»ˆç»“æœ:")
    print(final_data.get("final_output", {}))

    print("\nğŸ“ˆ æ‰§è¡Œç»Ÿè®¡:")
    stats = engine.get_execution_stats()

    # æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º
    def format_duration(seconds):
        if seconds < 1:
            return f"{seconds*1000:.1f}ms"
        elif seconds < 60:
            return f"{seconds:.2f}s"
        else:
            minutes = int(seconds // 60)
            remaining_seconds = seconds % 60
            return f"{minutes}åˆ†{remaining_seconds:.1f}ç§’"

    def format_timestamp(timestamp):
        from datetime import datetime

        return datetime.fromtimestamp(timestamp).strftime("%H:%M:%S")

    # æ˜¾ç¤ºå‹å¥½çš„ç»Ÿè®¡ä¿¡æ¯
    print(f"   â±ï¸  æ€»è€—æ—¶: {format_duration(stats.get('total_duration', 0))}")
    print(f"   ğŸ•  å¼€å§‹æ—¶é—´: {format_timestamp(stats.get('start_time', 0))}")
    print(f"   ğŸ•  ç»“æŸæ—¶é—´: {format_timestamp(stats.get('end_time', 0))}")
    print(f"   ğŸ”„  è¶…æ­¥æ•°é‡: {stats.get('total_supersteps', 0)}")
    print(f"   âš™ï¸  æ‰§è¡ŒèŠ‚ç‚¹: {stats.get('total_nodes_executed', 0)}")
    print(f"   ğŸ“¨  æ¶ˆæ¯ä¼ é€’: {stats.get('messages_sent', 0)}")

    # æ˜¾ç¤ºèŠ‚ç‚¹æ‰§è¡Œæ—¶é—´è¯¦æƒ…
    node_times = stats.get("node_execution_times", {})
    if node_times:
        print("   â±ï¸  èŠ‚ç‚¹è€—æ—¶è¯¦æƒ…:")
        for node_id, duration in node_times.items():
            print(f"      â€¢ {node_id}: {format_duration(duration)}")

    return {
        "success": True,
        "final_state": final_data,
        "execution_stats": stats,
        "execution_time": execution_time,
    }


if __name__ == "__main__":
    asyncio.run(run_siliconflow_demo())
