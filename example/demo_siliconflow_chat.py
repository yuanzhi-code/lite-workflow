import asyncio
import os
import sys
import time

# ç¡®ä¿èƒ½å¯¼å…¥lite_workflowæ¨¡å—
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "..")))

from lite_workflow.components.chat_models import ChatSiliconFlow, Message
from lite_workflow.core.error_handler import ErrorHandler
from lite_workflow.core.state_manager import StateManager
from lite_workflow.definitions.edge import Edge
from lite_workflow.definitions.graph import Graph
from lite_workflow.definitions.node import (
    create_async_function_node,
    create_function_node,
)
from lite_workflow.engine.pregel_engine import PregelEngine

# åˆå§‹åŒ–ç¡…åŸºæµåŠ¨æ¨¡å‹
# è¯·ç¡®ä¿å·²è®¾ç½® OPENAI_API_KEY æˆ– SILICONFLOW_API_KEY ç¯å¢ƒå˜é‡
# ä¾‹å¦‚: export SILICONFLOW_API_KEY='YOUR_API_KEY'
try:
    silicon_flow_model = ChatSiliconFlow(model="Qwen/Qwen3-8B")  # æ‚¨ä¹Ÿå¯ä»¥å°è¯•å…¶ä»–æ¨¡å‹
    print("âœ… ç¡…åŸºæµåŠ¨æ¨¡å‹åˆå§‹åŒ–æˆåŠŸï¼")
except ValueError as e:
    print(f"âŒ ç¡…åŸºæµåŠ¨æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿å·²è®¾ç½® OPENAI_API_KEY æˆ– SILICONFLOW_API_KEY ç¯å¢ƒå˜é‡ã€‚")
    exit(1)


# ğŸ¯ èŠ‚ç‚¹å®ç°


def initial_prompt_node(inputs: dict) -> dict:
    """å¤„ç†åˆå§‹è¾“å…¥å¹¶å‡†å¤‡å¥½è¿›è¡Œå¤§æ¨¡å‹è°ƒç”¨ã€‚"""
    prompt = inputs.get("prompt", "è¯·ç”¨ä¸­æ–‡ç®€æ´ä»‹ç»ä¸€ä¸‹æœºå™¨å­¦ä¹ ã€‚")
    print(f"ğŸ“ [å¼€å§‹] æ¥æ”¶åˆ°æç¤º: {prompt}")
    return {"prompt": prompt}


async def silicon_flow_chat_node(inputs: dict) -> dict:
    """è°ƒç”¨ç¡…åŸºæµåŠ¨æ¨¡å‹ç”Ÿæˆå›å¤ã€‚"""
    user_prompt = inputs.get("prompt", "")  # å°† "user_prompt" æ”¹ä¸º "prompt"
    print(f"ğŸ’¬ [ç¡…åŸºæµåŠ¨] æ¥æ”¶åˆ°çš„è¾“å…¥ (inputs): {inputs}")  # æ·»åŠ è¿™è¡Œæ¥è°ƒè¯•
    if not user_prompt:
        return {"error": "æœªæä¾›ç”¨æˆ·æç¤º", "model_response": ""}

    print("ğŸ’¬ [ç¡…åŸºæµåŠ¨] æ­£åœ¨è°ƒç”¨æ¨¡å‹ç”Ÿæˆå›å¤...")
    try:
        # å°†å­—ç¬¦ä¸²æç¤ºè½¬æ¢ä¸ºMessageå¯¹è±¡åˆ—è¡¨
        messages = [Message.user(user_prompt)]
        result = await silicon_flow_model.ainvoke(messages)
        model_response = result.message.content
        print(f"âœ¨ [ç¡…åŸºæµåŠ¨] æ¨¡å‹å›å¤: {model_response[:100]}...")  # æ‰“å°éƒ¨åˆ†å›å¤
        return {"model_response": model_response, "original_prompt": user_prompt}
    except Exception as e:
        print(f"âŒ [ç¡…åŸºæµåŠ¨] æ¨¡å‹è°ƒç”¨å¤±è´¥: {e}")
        return {"error": str(e), "model_response": ""}


def final_output_node(inputs: dict) -> dict:
    """æ•´ç†å¹¶è¾“å‡ºæœ€ç»ˆç»“æœã€‚"""
    original_prompt = inputs.get("original_prompt", "æ— ")
    model_response = inputs.get("model_response", "æ— å›å¤")
    error = inputs.get("error", None)

    print("ğŸ‰ [å®Œæˆ] æœ€ç»ˆç»“æœï¼š")
    print(f"   åŸå§‹æç¤º: {original_prompt}")
    if error:
        print(f"   é”™è¯¯ä¿¡æ¯: {error}")
    print(f"   æ¨¡å‹å›å¤: {model_response}")

    return {
        "final_output": {
            "original_prompt": original_prompt,
            "model_response": model_response,
            "error": error,
        }
    }


# ğŸ—ï¸ å›¾ç»“æ„æ„å»ºå™¨


def create_siliconflow_graph() -> Graph:
    """åˆ›å»ºåŒ…å«ç¡…åŸºæµåŠ¨è°ƒç”¨çš„å›¾ç»“æ„ã€‚"""
    nodes = [
        create_function_node("initial_prompt", initial_prompt_node),
        create_async_function_node(
            "silicon_flow_chat", silicon_flow_chat_node
        ),  # æ ‡è®°ä¸ºå¼‚æ­¥èŠ‚ç‚¹
        create_function_node("final_output", final_output_node),
    ]

    edges = [
        Edge("initial_prompt", "silicon_flow_chat"),
        Edge("silicon_flow_chat", "final_output"),
    ]

    return Graph("siliconflow_chat_demo", nodes, edges, "initial_prompt")


# ğŸš€ æ‰§è¡Œå‡½æ•°


async def run_siliconflow_demo():
    """è¿è¡Œç¡…åŸºæµåŠ¨å›¾æ¼”ç¤ºã€‚"""
    print("ğŸ¯ ç¡…åŸºæµåŠ¨èŠå¤©å›¾æ¼”ç¤º")
    print("=" * 60)

    graph = create_siliconflow_graph()
    print(f"ğŸ“Š å›¾å·²æ„å»º: {len(graph.nodes)} èŠ‚ç‚¹, {len(graph.edges)} è¾¹")
    print(f"   èµ·å§‹èŠ‚ç‚¹: {graph.start_node}")
    print(f"   ç»ˆæ­¢èŠ‚ç‚¹: {[n for n in graph.nodes if graph.is_terminal(n)]}")

    print(f"âœ… å›¾éªŒè¯: {graph.validate_cycles()}")

    initial_state = {"prompt": "è¯·è§£é‡Šä¸€ä¸‹å¤§è¯­è¨€æ¨¡å‹çš„å·¥ä½œåŸç†ï¼Œç”¨100å­—ä»¥å†…æ¦‚æ‹¬ã€‚"}
    state_manager = StateManager(initial_state)
    error_handler = ErrorHandler()

    engine = PregelEngine(graph, state_manager, error_handler)

    print("\nğŸ”„ å¼€å§‹æ‰§è¡Œ...")
    print(f"åˆå§‹çŠ¶æ€: {initial_state}")

    start_time = time.time()
    final_state = await engine.execute_async()  # ä½¿ç”¨å¼‚æ­¥æ‰§è¡Œ
    execution_time = time.time() - start_time

    print("\nğŸ‰ æ‰§è¡Œå®Œæˆ!")
    print(f"æ€»è€—æ—¶: {execution_time:.2f}s")

    final_data = final_state.to_dict()
    print("\nï¿½ï¿½ æœ€ç»ˆç»“æœ:")
    print(f"å®Œæ•´æœ€ç»ˆæ•°æ®: {final_data}")  # æ·»åŠ æ­¤è¡Œ
    print(final_data.get("final_output", {}))

    print("\nğŸ“ˆ æ‰§è¡Œç»Ÿè®¡:")
    stats = engine.get_execution_stats()
    for key, value in stats.items():
        if key != "node_execution_times":
            print(f"   {key}: {value}")

    return {
        "success": True,
        "final_state": final_data,
        "execution_stats": stats,
        "execution_time": execution_time,
    }


if __name__ == "__main__":
    asyncio.run(run_siliconflow_demo())
