# Lite Workflow è®¾è®¡æ–‡æ¡£

## 1. é¡¹ç›®æ¦‚è¿°

### 1.1 é¡¹ç›®èƒŒæ™¯ä¸ç›®æ ‡

Lite Workflow æ˜¯ä¸€ä¸ªç°ä»£åŒ–çš„ä¸­æ–‡å‹å¥½å·¥ä½œæµç¼–æ’ç³»ç»Ÿï¼Œçµæ„Ÿæ¥æºäº Google Pregel å›¾è®¡ç®—æ¡†æ¶ï¼Œä¸“ä¸ºæ„å»ºå¤æ‚çš„ AI å·¥ä½œæµè€Œè®¾è®¡ã€‚

**æ ¸å¿ƒç›®æ ‡ï¼š**
- æä¾›åŸºäºå›¾ç»“æ„çš„ä¼˜é›…å·¥ä½œæµç¼–æ’
- æ”¯æŒå¤æ‚çš„å¹¶è¡Œå¤„ç†ã€æ¡ä»¶åˆ†æ”¯å’Œè¿­ä»£æ¨ç†
- åŸç”Ÿä¸­æ–‡å‹å¥½ï¼Œé™ä½ä¸­æ–‡å¼€å‘è€…ä½¿ç”¨é—¨æ§›
- ç°ä»£åŒ– Python æŠ€æœ¯æ ˆï¼Œç±»å‹å®‰å…¨ã€å¼‚æ­¥ä¼˜å…ˆ

### 1.2 äº§å“æ„¿æ™¯

æˆä¸ºä¸­æ–‡ AI å¼€å‘è€…çš„é¦–é€‰å·¥ä½œæµç¼–æ’æ¡†æ¶ï¼Œä½¿å¼€å‘è€…èƒ½å¤Ÿä»¥ç›´è§‚ã€æ¨¡å—åŒ–å’Œé«˜æ•ˆçš„æ–¹å¼æ„å»ºä»»ä½•å¤æ‚åº¦çš„ AI åº”ç”¨ã€‚

## 2. æ ¸å¿ƒæ¶æ„è®¾è®¡

### 2.1 å›¾ç»“æ„æŠ½è±¡ (Node-Edge Graph)

#### æ ¸å¿ƒæ¦‚å¿µ
- **Nodeï¼ˆèŠ‚ç‚¹ï¼‰**: ç‹¬ç«‹çš„è®¡ç®—å•å…ƒï¼Œå¯ä»¥æ˜¯ LLM è°ƒç”¨ã€å·¥å…·æ‰§è¡Œã€è‡ªå®šä¹‰å‡½æ•°
- **Edgeï¼ˆè¾¹ï¼‰**: æ•°æ®æµå’Œæ§åˆ¶æµçš„æ–¹å‘ï¼Œæ”¯æŒæ¡ä»¶è·¯ç”±
- **Graphï¼ˆå›¾ï¼‰**: èŠ‚ç‚¹å’Œè¾¹çš„é›†åˆï¼Œå®šä¹‰å®Œæ•´çš„å·¥ä½œæµç»“æ„

#### æ¶æ„ä¼˜åŠ¿
```python
# é¡ºåºæ‰§è¡Œ
workflow.chain("æ­¥éª¤1", "æ­¥éª¤2", "æ­¥éª¤3")

# å¹¶è¡Œæ‰§è¡Œ (Fan-out)
workflow.add_edge("å¼€å§‹", "åˆ†æ”¯A")
workflow.add_edge("å¼€å§‹", "åˆ†æ”¯B")

# æ¡ä»¶åˆ†æ”¯
edge = Edge("åˆ¤æ–­", "åˆ†æ”¯A", condition=lambda outputs: outputs.get("score") > 50)

# å¾ªç¯è¿­ä»£
edge = Edge("è´¨é‡é—¨", "æ”¹è¿›å™¨", condition=lambda outputs: outputs.get("should_continue"))
```

### 2.2 Pregel é£æ ¼æ‰§è¡Œå¼•æ“

#### è¶…æ­¥è®¡ç®— (Superstep)
- **æ¶ˆæ¯ä¼ é€’**: èŠ‚ç‚¹é—´é€šè¿‡æ¶ˆæ¯é€šä¿¡ï¼Œè€Œéå…±äº«çŠ¶æ€
- **çŠ¶æ€åŒæ­¥**: è‡ªåŠ¨åˆå¹¶å¹¶è¡Œæ›´æ–°ï¼Œç¡®ä¿ä¸€è‡´æ€§
- **å¢é‡æ›´æ–°**: åªä¼ é€’çŠ¶æ€å˜åŒ–ï¼Œé¿å…å®Œæ•´çŠ¶æ€å¤åˆ¶

#### æ‰§è¡Œæµç¨‹
```
è¶…æ­¥ 0: åˆå§‹åŒ– â†’ æ´»è·ƒèŠ‚ç‚¹ [å¼€å§‹]
è¶…æ­¥ 1: æ‰§è¡Œå¼€å§‹èŠ‚ç‚¹ â†’ å‘é€æ¶ˆæ¯åˆ° [åˆ†æ”¯A, åˆ†æ”¯B]
è¶…æ­¥ 2: å¹¶è¡Œæ‰§è¡Œåˆ†æ”¯ â†’ å‘é€æ¶ˆæ¯åˆ° [èšåˆå™¨]
è¶…æ­¥ 3: æ‰§è¡Œèšåˆå™¨ â†’ å‘é€æ¶ˆæ¯åˆ° [è´¨é‡é—¨]
è¶…æ­¥ 4: æ¡ä»¶åˆ¤æ–­ â†’ å†³å®šæ˜¯å¦ç»§ç»­å¾ªç¯
```

### 2.3 ç°ä»£åŒ–æŠ€æœ¯æ ˆ

#### ç±»å‹å®‰å…¨
```python
from typing import Any, Callable
from typing_extensions import TypeAlias

NodeId: TypeAlias = str
NodeFunction: TypeAlias = Callable[..., dict[str, Any]]
```

#### å¼‚æ­¥ä¼˜å…ˆ
```python
async def async_node(inputs: dict, **context) -> dict:
    await asyncio.sleep(0.1)
    return {"result": "processed"}

# è‡ªåŠ¨å¤„ç†åŒæ­¥/å¼‚æ­¥è½¬æ¢
node = Node("async_node", async_node)
```

#### ä¸­æ–‡å‹å¥½
```python
# æ”¯æŒä¸­æ–‡èŠ‚ç‚¹åå’Œé”™è¯¯ä¿¡æ¯
workflow = Workflow("æ•°æ®åˆ†æå·¥ä½œæµ", {"æ•°æ®": "åŸå§‹æ•°æ®"})
workflow.add_node("æ•°æ®æ¸…æ´—å™¨", clean_data)
workflow.add_node("ç»“æœåˆ†æå™¨", analyze_results)
```

## 3. æ ¸å¿ƒç»„ä»¶è®¾è®¡

### 3.1 åŒ…ç»“æ„è®¾è®¡

```
src/lite_workflow/
â”œâ”€â”€ definitions/     # æ ¸å¿ƒå®šä¹‰
â”‚   â”œâ”€â”€ node.py      # èŠ‚ç‚¹å®šä¹‰å’Œåè®®
â”‚   â”œâ”€â”€ edge.py      # è¾¹å®šä¹‰å’Œæ¡ä»¶
â”‚   â”œâ”€â”€ graph.py     # å›¾ç»“æ„å’ŒéªŒè¯
â”‚   â”œâ”€â”€ state.py     # çŠ¶æ€æŠ½è±¡
â”‚   â””â”€â”€ message.py   # æ¶ˆæ¯å®šä¹‰
â”œâ”€â”€ core/           # åŸºç¡€è®¾æ–½
â”‚   â”œâ”€â”€ state_manager.py  # çŠ¶æ€ç®¡ç†å’Œå†²çªè§£å†³
â”‚   â”œâ”€â”€ error_handler.py  # é”™è¯¯å¤„ç†å’Œæ¢å¤
â”‚   â”œâ”€â”€ event_bus.py      # äº‹ä»¶æ€»çº¿
â”‚   â””â”€â”€ logger.py         # æ—¥å¿—ç³»ç»Ÿ
â”œâ”€â”€ engine/         # æ‰§è¡Œå¼•æ“
â”‚   â”œâ”€â”€ pregel_engine.py  # Pregelé£æ ¼å¼•æ“
â”‚   â”œâ”€â”€ execution_engine.py # æŠ½è±¡æ‰§è¡Œå¼•æ“
â”‚   â””â”€â”€ workflow.py       # é«˜çº§å·¥ä½œæµAPI
â”œâ”€â”€ components/     # ç»„ä»¶å®ç°
â”‚   â”œâ”€â”€ chat_models.py    # LLMé›†æˆ
â”‚   â”œâ”€â”€ function_nodes.py # Pythonå‡½æ•°èŠ‚ç‚¹
â”‚   â””â”€â”€ tools.py          # å·¥å…·ç³»ç»Ÿ
â””â”€â”€ cli.py          # å‘½ä»¤è¡Œæ¥å£
```

### 3.2 æ ¸å¿ƒç»„ä»¶è¯¦è§£

#### èŠ‚ç‚¹ç³»ç»Ÿ (Node System)
```python
@dataclass
class NodeConfig:
    timeout: float | None = None
    retry_count: int = 0
    retry_delay: float = 1.0
    metadata: dict[str, Any] = field(default_factory=dict)

class Node:
    def __init__(self, node_id: NodeId, executor: NodeExecutor, config: NodeConfig | None = None):
        self.node_id = node_id
        self.executor = executor
        self.config = config or NodeConfig()
    
    async def execute_async(self, inputs: dict, **context) -> dict:
        # è‡ªåŠ¨å¤„ç†åŒæ­¥/å¼‚æ­¥æ‰§è¡Œå™¨
        if asyncio.iscoroutinefunction(self.executor):
            return await self.executor(inputs, **context)
        else:
            return await asyncio.to_thread(self.executor, inputs, **context)
```

#### çŠ¶æ€ç®¡ç†ç³»ç»Ÿ (State Management)
```python
class StateManager:
    def __init__(self, initial_state: dict | None = None):
        self._state = InMemoryState(initial_state)
        self._lock = threading.RLock()
        self._merge_strategies: dict[str, MergeStrategy] = {}
    
    def update(self, updates: dict, strategy: UpdateStrategy = UpdateStrategy.OVERWRITE):
        # æ”¯æŒå¤šç§æ›´æ–°ç­–ç•¥ï¼šè¦†ç›–ã€åˆå¹¶ã€å¿½ç•¥ã€æŠ›å‡ºå¼‚å¸¸
        with self._lock:
            for key, new_value in updates.items():
                if strategy == UpdateStrategy.MERGE:
                    self._merge_value(key, new_value)
                else:
                    self.set(key, new_value)
```

#### å·¥å…·ç³»ç»Ÿ (Tool System)
```python
# è£…é¥°å™¨æ–¹å¼
@tool(name="calculator", description="æ‰§è¡Œæ•°å­¦è®¡ç®—")
def calculate(expression: str) -> str:
    try:
        result = eval(expression)
        return f"è®¡ç®—ç»“æœ: {expression} = {result}"
    except Exception as e:
        return f"è®¡ç®—é”™è¯¯: {e}"

# ç±»ç»§æ‰¿æ–¹å¼
class SearchTool(BaseTool):
    def __init__(self):
        super().__init__(name="search", description="æœç´¢ç½‘ç»œä¿¡æ¯")
    
    def _run(self, query: str) -> str:
        return f"æœç´¢ç»“æœ: å…³äº'{query}'çš„ä¿¡æ¯..."
    
    async def _arun(self, query: str) -> str:
        await asyncio.sleep(0.1)
        return f"å¼‚æ­¥æœç´¢ç»“æœ: å…³äº'{query}'çš„ä¿¡æ¯..."

# å·¥å…·æ³¨å†Œå’Œæ‰§è¡Œ
registry = create_tool_registry()
registry.register_tool(calculate)
registry.register(SearchTool())

result = registry.execute_tool("calculator", expression="2 + 3 * 4")
```

### 3.3 æ‰§è¡Œå¼•æ“è®¾è®¡

#### Pregel å¼•æ“æ ¸å¿ƒé€»è¾‘
```python
class PregelEngine(ExecutionEngine):
    async def execute_async(self) -> State:
        current_messages = self._initialize_messages()
        superstep = 0
        
        while superstep < self.config.max_iterations:
            if not any(current_messages.values()):
                break
            
            # æ‰§è¡Œè¶…æ­¥
            new_messages = await self._execute_superstep_async(current_messages, superstep)
            current_messages = new_messages
            superstep += 1
        
        return self.state_manager.get_state()
    
    async def _execute_superstep_async(self, messages: dict, superstep: int):
        # 1. è¯†åˆ«æ´»è·ƒèŠ‚ç‚¹
        active_nodes = [node_id for node_id, msgs in messages.items() if msgs]
        
        # 2. å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰æ´»è·ƒèŠ‚ç‚¹
        tasks = [self._execute_node_async(node_id, messages[node_id], superstep) 
                for node_id in active_nodes]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # 3. æ”¶é›†æ–°æ¶ˆæ¯
        new_messages = defaultdict(list)
        for node_id, result in zip(active_nodes, results):
            if isinstance(result, Exception):
                # é”™è¯¯å¤„ç†
                continue
            
            # å‘é€æ¶ˆæ¯åˆ°é‚»å±…èŠ‚ç‚¹
            outgoing_edges = self.graph.get_outgoing_edges(node_id)
            for edge in outgoing_edges:
                if edge.should_traverse(result, self.state_manager.get_state()):
                    new_messages[edge.target_id].append(result)
        
        return new_messages
```

## 4. é«˜çº§åŠŸèƒ½è®¾è®¡

### 4.1 å¹¶è¡Œå¤„ç†æ¨¡å¼

#### Fan-out (æ‰‡å‡º)
```python
# ä¸€ä¸ªèŠ‚ç‚¹è¾“å‡ºåˆ°å¤šä¸ªå¹¶è¡ŒèŠ‚ç‚¹
edges = [
    Edge("start", "branch_a"),
    Edge("start", "branch_b"), 
    Edge("start", "branch_c")
]

# æ‰§è¡Œæ—¶è‡ªåŠ¨å¹¶è¡Œå¤„ç†
# è¶…æ­¥ 1: start â†’ [branch_a, branch_b, branch_c] (å¹¶è¡Œ)
# è¶…æ­¥ 2: [branch_a, branch_b, branch_c] â†’ aggregator (ç­‰å¾…æ‰€æœ‰å®Œæˆ)
```

#### Fan-in (æ‰‡å…¥)
```python
# å¤šä¸ªèŠ‚ç‚¹æ±‡èšåˆ°ä¸€ä¸ªèšåˆèŠ‚ç‚¹
edges = [
    Edge("branch_a", "aggregator"),
    Edge("branch_b", "aggregator"),
    Edge("branch_c", "aggregator")
]

# çŠ¶æ€ç®¡ç†å™¨è‡ªåŠ¨åˆå¹¶å¤šä¸ªè¾“å…¥
def aggregator(inputs: dict) -> dict:
    # inputs åŒ…å«æ‰€æœ‰ä¸Šæ¸¸èŠ‚ç‚¹çš„è¾“å‡º
    return {"aggregated": sum(inputs.values())}
```

### 4.2 æ¡ä»¶è¾¹å’ŒåŠ¨æ€è·¯ç”±

```python
def quality_gate(inputs: dict) -> dict:
    score = inputs.get("score", 0)
    return {
        "should_continue": score < 80,
        "score": score
    }

# æ¡ä»¶è¾¹
edge = Edge("quality_gate", "improver", 
           condition=lambda outputs, state: outputs.get("should_continue", False))

# æ¡ä»¶è¾¹å®ç°
def should_traverse(self, outputs: dict, state: dict) -> bool:
    if self.condition is None:
        return True
    return self.condition(outputs, state)
```

### 4.3 å¾ªç¯å’Œè¿­ä»£

```python
# è´¨é‡é—¨æ§å¾ªç¯
def quality_gate(inputs: dict) -> dict:
    score = inputs.get("score", 0)
    iteration = inputs.get("iteration", 0)
    
    should_continue = score < 80 and iteration < 3
    return {
        "should_continue": should_continue,
        "iteration": iteration + 1,
        "score": score
    }

def improvement_engine(inputs: dict) -> dict:
    iteration = inputs.get("iteration", 0)
    # æ¨¡æ‹Ÿæ”¹è¿›è¿‡ç¨‹
    improved_score = 60 + iteration * 10
    return {
        "score": improved_score,
        "iteration": iteration
    }

# å¾ªç¯è¾¹
edges = [
    Edge("quality_gate", "improvement_engine", 
         condition=lambda outputs: outputs.get("should_continue")),
    Edge("improvement_engine", "quality_gate")
]
```

## 5. ä½¿ç”¨æ¨¡å¼è®¾è®¡

### 5.1 é«˜çº§ API (Workflow)

```python
from lite_workflow import Workflow

# åˆ›å»ºå·¥ä½œæµ
workflow = Workflow("æ•°æ®åˆ†æ", {"data": "åŸå§‹æ•°æ®"})

# æ·»åŠ èŠ‚ç‚¹
workflow.add_node("æ¸…æ´—å™¨", lambda x: {"clean": x["data"].strip()})
workflow.add_node("åˆ†æå™¨", lambda x: {"result": f"åˆ†æ: {x['clean']}"})

# è¿æ¥èŠ‚ç‚¹
workflow.chain("æ¸…æ´—å™¨", "åˆ†æå™¨")

# æ‰§è¡Œ
result = workflow.run()
print(result.final_state.to_dict())
```

### 5.2 ä½çº§ API (Graph + Engine)

```python
from lite_workflow.definitions import Node, Edge, Graph
from lite_workflow.engine import PregelEngine

# åˆ›å»ºèŠ‚ç‚¹
nodes = [
    Node("start", lambda x: {"value": 1}),
    Node("double", lambda x: {"value": x["value"] * 2}),
    Node("triple", lambda x: {"value": x["value"] * 3}),
    Node("aggregate", lambda x: {"result": x["value"]})
]

# åˆ›å»ºè¾¹
edges = [
    Edge("start", "double"),
    Edge("start", "triple"),
    Edge("double", "aggregate"),
    Edge("triple", "aggregate")
]

# æ„å»ºå›¾
graph = Graph("å¹¶è¡Œå¤„ç†", nodes, edges, "start")
engine = PregelEngine(graph, {"value": 10})
result = engine.execute()
```

### 5.3 LLM é›†æˆæ¨¡å¼

```python
from lite_workflow.components import ChatOpenAI

def call_llm(inputs: dict) -> dict:
    model = ChatOpenAI(model="gpt-3.5-turbo")
    response = model.invoke(inputs["question"])
    return {"answer": response.content}

def format_response(inputs: dict) -> dict:
    answer = inputs["answer"]
    return {"formatted": f"AIå›ç­”: {answer}"}

workflow = Workflow("AIåŠ©æ‰‹", {"question": "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ"})
workflow.add_node("llm", call_llm)
workflow.add_node("formatter", format_response)
workflow.chain("llm", "formatter")

result = workflow.run()
```

## 6. æ‰©å±•æ€§è®¾è®¡

### 6.1 è‡ªå®šä¹‰èŠ‚ç‚¹ç±»å‹

```python
class CustomNode(Node):
    def __init__(self, node_id: str, **kwargs):
        super().__init__(node_id, self._execute, **kwargs)
    
    def _execute(self, inputs: dict, **context) -> dict:
        # è‡ªå®šä¹‰æ‰§è¡Œé€»è¾‘
        return {"custom_result": "processed"}
```

### 6.2 è‡ªå®šä¹‰å·¥å…·

```python
class CustomTool(BaseTool):
    def _run(self, **kwargs) -> str:
        # åŒæ­¥å®ç°
        return "åŒæ­¥ç»“æœ"
    
    async def _arun(self, **kwargs) -> str:
        # å¼‚æ­¥å®ç°
        return "å¼‚æ­¥ç»“æœ"
```

### 6.3 è‡ªå®šä¹‰æ‰§è¡Œå¼•æ“

```python
class CustomEngine(ExecutionEngine):
    async def execute_async(self) -> State:
        # è‡ªå®šä¹‰æ‰§è¡Œé€»è¾‘
        pass
```

## 7. æ€§èƒ½ä¼˜åŒ–è®¾è®¡

### 7.1 å¼‚æ­¥æ‰§è¡Œ

- **èŠ‚ç‚¹çº§åˆ«**: è‡ªåŠ¨æ£€æµ‹åŒæ­¥/å¼‚æ­¥å‡½æ•°ï¼Œä½¿ç”¨ `asyncio.to_thread` å¤„ç†åŒæ­¥å‡½æ•°
- **å›¾çº§åˆ«**: å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰æ´»è·ƒèŠ‚ç‚¹
- **å·¥å…·çº§åˆ«**: æ”¯æŒåŒæ­¥å’Œå¼‚æ­¥å·¥å…·è°ƒç”¨

### 7.2 çŠ¶æ€ç®¡ç†ä¼˜åŒ–

- **å¢é‡æ›´æ–°**: åªä¼ é€’çŠ¶æ€å˜åŒ–ï¼Œé¿å…å®Œæ•´çŠ¶æ€å¤åˆ¶
- **æ™ºèƒ½åˆå¹¶**: è‡ªåŠ¨å¤„ç†å­—å…¸å’Œåˆ—è¡¨çš„åˆå¹¶
- **çº¿ç¨‹å®‰å…¨**: ä½¿ç”¨ RLock ç¡®ä¿å¹¶å‘å®‰å…¨

### 7.3 å†…å­˜ç®¡ç†

- **æ¶ˆæ¯ä¼ é€’**: é¿å…å…±äº«çŠ¶æ€ï¼Œå‡å°‘å†…å­˜å ç”¨
- **çŠ¶æ€å¿«ç…§**: æ”¯æŒçŠ¶æ€å¿«ç…§å’Œæ¢å¤
- **åƒåœ¾å›æ”¶**: åŠæ—¶æ¸…ç†è¿‡æœŸçš„æ¶ˆæ¯å’ŒçŠ¶æ€

## 8. é”™è¯¯å¤„ç†è®¾è®¡

### 8.1 åˆ†å±‚é”™è¯¯å¤„ç†

```python
class ErrorHandler:
    async def handle_error_async(self, node_id: str, error: Exception, context: dict):
        # 1. è®°å½•é”™è¯¯
        self.logger.error(f"Node {node_id} failed: {error}")
        
        # 2. å°è¯•æ¢å¤
        if self.retry_count < self.max_retries:
            return await self._retry_node(node_id, context)
        
        # 3. é™çº§å¤„ç†
        return await self._fallback_processing(node_id, error, context)
```

### 8.2 é”™è¯¯æ¢å¤ç­–ç•¥

- **é‡è¯•æœºåˆ¶**: æ”¯æŒæŒ‡æ•°é€€é¿é‡è¯•
- **é™çº§å¤„ç†**: æä¾›é»˜è®¤å€¼æˆ–ç®€åŒ–å¤„ç†
- **é”™è¯¯ä¼ æ’­**: å‘ä¸Šå±‚ä¼ æ’­ä¸å¯æ¢å¤çš„é”™è¯¯

## 9. ç›‘æ§å’Œæ—¥å¿—è®¾è®¡

### 9.1 äº‹ä»¶æ€»çº¿

```python
class EventBus:
    def emit(self, event: Event):
        # å‘å¸ƒäº‹ä»¶åˆ°æ‰€æœ‰ç›‘å¬å™¨
        for listener in self._listeners:
            listener(event)

# äº‹ä»¶ç±»å‹
class SuperStepEvent(Event):
    def __init__(self, superstep: int, active_nodes: list, completed_nodes: list):
        super().__init__("superstep", {
            "superstep": superstep,
            "active_nodes": active_nodes,
            "completed_nodes": completed_nodes
        })
```

### 9.2 æ—¥å¿—ç³»ç»Ÿ

```python
class Logger:
    def log_workflow_start(self, graph_id: str):
        self.info(f"ğŸš€ å·¥ä½œæµ {graph_id} å¼€å§‹æ‰§è¡Œ")
    
    def log_workflow_complete(self, graph_id: str, duration: float, final_state: dict):
        self.info(f"âœ… å·¥ä½œæµ {graph_id} å®Œæˆï¼Œè€—æ—¶ {duration:.2f}s")
```

## 10. éƒ¨ç½²å’Œé…ç½®

### 10.1 ç¯å¢ƒé…ç½®

```python
# æ”¯æŒç¯å¢ƒå˜é‡é…ç½®
import os
model = OpenAIChatModel(
    api_key=os.getenv("OPENAI_API_KEY"),
    base_url=os.getenv("OPENAI_BASE_URL")
)
```

### 10.2 å‘½ä»¤è¡Œå·¥å…·

```bash
# è¿è¡Œæ¼”ç¤º
python -m lite_workflow --demo

# è¿è¡Œå·¥ä½œæµæ–‡ä»¶
python -m lite_workflow --workflow path/to/workflow.py

# è¯¦ç»†æ—¥å¿—
python -m lite_workflow --demo --verbose
```

## 11. æœªæ¥æ‰©å±•è®¡åˆ’

### 11.1 çŸ­æœŸç›®æ ‡ (MVPå)

- **æŒä¹…åŒ–**: æ”¯æŒå·¥ä½œæµçŠ¶æ€æŒä¹…åŒ–åˆ°æ•°æ®åº“
- **å¯è§†åŒ–**: æä¾›å›¾æ‰§è¡Œè¿‡ç¨‹çš„å¯è§†åŒ–ç•Œé¢
- **ç›‘æ§**: æ·»åŠ æ€§èƒ½ç›‘æ§å’ŒæŒ‡æ ‡æ”¶é›†
- **ç‰ˆæœ¬æ§åˆ¶**: æ”¯æŒå·¥ä½œæµå®šä¹‰çš„ç‰ˆæœ¬ç®¡ç†

### 11.2 é•¿æœŸç›®æ ‡

- **åˆ†å¸ƒå¼æ‰§è¡Œ**: æ”¯æŒè·¨æœºå™¨çš„åˆ†å¸ƒå¼å·¥ä½œæµæ‰§è¡Œ
- **å®æ—¶æµå¤„ç†**: æ”¯æŒå®æ—¶æ•°æ®æµå¤„ç†
- **æœºå™¨å­¦ä¹ é›†æˆ**: æ·±åº¦é›†æˆ ML æ¡†æ¶
- **äº‘åŸç”Ÿ**: æ”¯æŒ Kubernetes éƒ¨ç½²

---

è¿™ä¸ªè®¾è®¡æ–‡æ¡£åŸºäºå®é™…å®ç°ï¼Œæä¾›äº†å®Œæ•´çš„æ¶æ„æŒ‡å¯¼ï¼Œç¡®ä¿ç³»ç»Ÿçš„å¯æ‰©å±•æ€§ã€å¯ç»´æŠ¤æ€§å’Œé«˜æ€§èƒ½ã€‚