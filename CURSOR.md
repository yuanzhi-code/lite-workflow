# Lite Workflow - AIåŠ©æ‰‹å¼€å‘æŒ‡å—

> è¿™æ˜¯ä¸€ä¸ªç»™AIåŠ©æ‰‹ï¼ˆå¦‚Claudeã€Cursor AIç­‰ï¼‰çœ‹çš„é¡¹ç›®æ–‡æ¡£ï¼Œå¸®åŠ©å¿«é€Ÿç†è§£é¡¹ç›®æ¶æ„å’Œå¼€å‘æ¨¡å¼ã€‚

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

**Lite Workflow** æ˜¯ä¸€ä¸ªç°ä»£åŒ–çš„ä¸­æ–‡å‹å¥½å·¥ä½œæµç¼–æ’ç³»ç»Ÿï¼Œçµæ„Ÿæ¥æºäº Google Pregel å›¾è®¡ç®—æ¡†æ¶ï¼Œä¸“ä¸ºæ„å»ºå¤æ‚çš„ AI å·¥ä½œæµè€Œè®¾è®¡ã€‚

### æ ¸å¿ƒç‰¹æ€§
- **å›¾ç¼–æ’**: åŸºäºèŠ‚ç‚¹-è¾¹çš„ä¼˜é›…å›¾ç»“æ„
- **Pregel é£æ ¼**: è¶…æ­¥è®¡ç®—ä¸æ¶ˆæ¯ä¼ é€’
- **å¹¶è¡Œæ‰§è¡Œ**: æ”¯æŒæ‰‡å…¥/æ‰‡å‡ºå’Œæ¡ä»¶è¾¹
- **å¾ªç¯æ”¯æŒ**: è¿­ä»£æ”¹è¿›ä¸è´¨é‡é—¨æ§
- **ç°ä»£ Python**: ç±»å‹å®‰å…¨ã€å¼‚æ­¥æ”¯æŒã€ä¸­æ–‡å‹å¥½

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### æ ¸å¿ƒæ¦‚å¿µ

#### 1. å›¾ç»“æ„ (Graph)
```
èŠ‚ç‚¹ (Node) â†â†’ è¾¹ (Edge) â†’ èŠ‚ç‚¹ (Node)
   â†“               â†‘
çŠ¶æ€ (State) â† æ¶ˆæ¯ä¼ é€’ â†’ çŠ¶æ€æ›´æ–°
```

#### 2. æ‰§è¡Œæ¨¡å¼
- **è¶…æ­¥ (Superstep)**: æ¯ä¸ªè¿­ä»£å¤„ç†æ‰€æœ‰æ´»è·ƒèŠ‚ç‚¹
- **æ¶ˆæ¯ä¼ é€’**: èŠ‚ç‚¹é—´é€šè¿‡æ¶ˆæ¯é€šä¿¡
- **çŠ¶æ€åŒæ­¥**: è‡ªåŠ¨åˆå¹¶å¹¶è¡Œæ›´æ–°

### åŒ…ç»“æ„

```
src/lite_workflow/
â”œâ”€â”€ definitions/     # æ ¸å¿ƒå®šä¹‰
â”‚   â”œâ”€â”€ node.py      # èŠ‚ç‚¹å®šä¹‰
â”‚   â”œâ”€â”€ edge.py      # è¾¹å®šä¹‰
â”‚   â”œâ”€â”€ graph.py     # å›¾ç»“æ„
â”‚   â”œâ”€â”€ state.py     # çŠ¶æ€ç®¡ç†
â”‚   â””â”€â”€ message.py   # æ¶ˆæ¯å®šä¹‰
â”œâ”€â”€ core/           # åŸºç¡€è®¾æ–½
â”‚   â”œâ”€â”€ state_manager.py  # çŠ¶æ€ç®¡ç†å™¨
â”‚   â”œâ”€â”€ error_handler.py  # é”™è¯¯å¤„ç†
â”‚   â”œâ”€â”€ event_bus.py      # äº‹ä»¶æ€»çº¿
â”‚   â””â”€â”€ logger.py         # æ—¥å¿—ç³»ç»Ÿ
â”œâ”€â”€ engine/         # æ‰§è¡Œå¼•æ“
â”‚   â”œâ”€â”€ pregel_engine.py  # Pregelé£æ ¼å¼•æ“
â”‚   â”œâ”€â”€ execution_engine.py # æŠ½è±¡æ‰§è¡Œå¼•æ“
â”‚   â””â”€â”€ workflow.py       # é«˜çº§å·¥ä½œæµ
â”œâ”€â”€ components/     # ç»„ä»¶å®ç°
â”‚   â”œâ”€â”€ chat_models.py    # LLMé›†æˆ
â”‚   â”œâ”€â”€ function_nodes.py # Pythonå‡½æ•°èŠ‚ç‚¹
â”‚   â””â”€â”€ tools.py          # å·¥å…·èŠ‚ç‚¹ï¼ˆLangChainé£æ ¼ï¼‰
â””â”€â”€ cli.py          # å‘½ä»¤è¡Œæ¥å£
```

## ğŸ”§ æ ¸å¿ƒç»„ä»¶è¯¦è§£

### 1. èŠ‚ç‚¹ç³»ç»Ÿ (Node System)

#### åŸºç¡€èŠ‚ç‚¹
```python
from lite_workflow.definitions import Node, NodeConfig

# åˆ›å»ºèŠ‚ç‚¹
node = Node(
    node_id="my_node",
    executor=lambda inputs, **context: {"result": "processed"},
    config=NodeConfig()
)
```

#### å‡½æ•°èŠ‚ç‚¹
```python
from lite_workflow.components import PythonFunctionNode, create_function_node

# æ–¹å¼1: ä½¿ç”¨è£…é¥°å™¨
@node("data_processor")
def process_data(inputs: dict) -> dict:
    return {"processed": inputs["data"].upper()}

# æ–¹å¼2: ç›´æ¥åˆ›å»º
def my_func(inputs: dict) -> dict:
    return {"output": inputs["value"] * 2}

node = create_function_node("multiplier", my_func)
```

### 2. å·¥å…·ç³»ç»Ÿ (Tool System) - LangChainé£æ ¼

#### å·¥å…·å®šä¹‰
```python
from lite_workflow import BaseTool, Tool, tool, ToolRegistry

# æ–¹å¼1: ä½¿ç”¨è£…é¥°å™¨
@tool(name="calculator", description="æ‰§è¡Œæ•°å­¦è®¡ç®—")
def calculate(expression: str) -> str:
    try:
        result = eval(expression)
        return f"è®¡ç®—ç»“æœ: {expression} = {result}"
    except Exception as e:
        return f"è®¡ç®—é”™è¯¯: {e}"

# æ–¹å¼2: ç»§æ‰¿BaseTool
class SearchTool(BaseTool):
    def __init__(self):
        super().__init__(name="search", description="æœç´¢ç½‘ç»œä¿¡æ¯")
    
    def _run(self, query: str) -> str:
        return f"æœç´¢ç»“æœ: å…³äº'{query}'çš„ä¿¡æ¯..."
    
    async def _arun(self, query: str) -> str:
        await asyncio.sleep(0.1)
        return f"å¼‚æ­¥æœç´¢ç»“æœ: å…³äº'{query}'çš„ä¿¡æ¯..."
```

#### å·¥å…·æ³¨å†Œå’Œæ‰§è¡Œ
```python
# åˆ›å»ºæ³¨å†Œè¡¨
registry = create_tool_registry()

# æ³¨å†Œå·¥å…·
registry.register_tool(calculate)
registry.register(SearchTool())

# æ‰§è¡Œå·¥å…·
result = registry.execute_tool("calculator", expression="2 + 3 * 4")
async_result = await registry.aexecute_tool("search", query="Python")

# å·¥å…·æ‰§è¡Œå™¨ï¼ˆç”¨äºLLMé›†æˆï¼‰
executor = ToolExecutor(registry)
tool_calls = [
    {
        "id": "call_1",
        "function": {
            "name": "calculator",
            "arguments": '{"expression": "10 + 20"}'
        }
    }
]
results = executor.execute_tool_calls(tool_calls)
```

### 3. LLMé›†æˆ (Chat Models)

```python
from lite_workflow.components import OpenAIChatModel, ChatOpenAI

# åŸºç¡€æ¨¡å‹
model = OpenAIChatModel(
    model="gpt-3.5-turbo",
    temperature=0.7
)

# å·¥å‚å‡½æ•°
model = ChatOpenAI(model="gpt-3.5-turbo")

# ä½¿ç”¨
result = model.invoke("è§£é‡Šæœºå™¨å­¦ä¹ ")
stream = model.stream("å†™ä¸€ä¸ªPythonå‡½æ•°")
```

### 4. å·¥ä½œæµæ„å»º (Workflow Building)

#### é«˜çº§API
```python
from lite_workflow import Workflow

# åˆ›å»ºå·¥ä½œæµ
workflow = Workflow("æ•°æ®åˆ†æ", {"data": "åŸå§‹æ•°æ®"})

# æ·»åŠ èŠ‚ç‚¹
workflow.add_node("æ¸…æ´—å™¨", lambda x: {"clean": x["data"].strip()})
workflow.add_node("åˆ†æå™¨", lambda x: {"result": f"åˆ†æ: {x['clean']}"})

# è¿æ¥èŠ‚ç‚¹
workflow.chain("æ¸…æ´—å™¨", "åˆ†æå™¨")
# æˆ–è€…
workflow.add_edge("æ¸…æ´—å™¨", "åˆ†æå™¨")

# æ‰§è¡Œ
result = workflow.run()
```

#### ä½çº§API
```python
from lite_workflow.definitions import Node, Edge, Graph
from lite_workflow.engine import PregelEngine

# åˆ›å»ºèŠ‚ç‚¹
nodes = [
    Node("start", lambda x: {"value": 1}),
    Node("double", lambda x: {"value": x["value"] * 2}),
    Node("triple", lambda x: {"value": x["value"] * 3}),
    Node("aggregate", lambda x: {"result": x["value"]})
]

# åˆ›å»ºè¾¹
edges = [
    Edge("start", "double"),
    Edge("start", "triple"),
    Edge("double", "aggregate"),
    Edge("triple", "aggregate")
]

# æ„å»ºå›¾
graph = Graph("å¹¶è¡Œå¤„ç†", nodes, edges, "start")
engine = PregelEngine(graph, {"value": 10})
result = engine.execute()
```

## ğŸš€ å¼€å‘æ¨¡å¼

### 1. èŠ‚ç‚¹å¼€å‘æ¨¡å¼

#### åŒæ­¥èŠ‚ç‚¹
```python
def sync_node(inputs: dict, **context) -> dict:
    """åŒæ­¥èŠ‚ç‚¹å‡½æ•°"""
    data = inputs.get("data", "")
    processed = data.upper()
    return {"result": processed}
```

#### å¼‚æ­¥èŠ‚ç‚¹
```python
async def async_node(inputs: dict, **context) -> dict:
    """å¼‚æ­¥èŠ‚ç‚¹å‡½æ•°"""
    data = inputs.get("data", "")
    await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿå¼‚æ­¥æ“ä½œ
    processed = data.upper()
    return {"result": processed}
```

### 2. å·¥å…·å¼€å‘æ¨¡å¼

#### ç®€å•å·¥å…·
```python
@tool(name="simple_tool")
def simple_tool(param: str) -> str:
    return f"å¤„ç†ç»“æœ: {param}"
```

#### å¤æ‚å·¥å…·
```python
class ComplexTool(BaseTool):
    def __init__(self):
        super().__init__(
            name="complex_tool",
            description="å¤æ‚å·¥å…·ç¤ºä¾‹"
        )
    
    def _run(self, **kwargs) -> str:
        # åŒæ­¥å®ç°
        return "åŒæ­¥ç»“æœ"
    
    async def _arun(self, **kwargs) -> str:
        # å¼‚æ­¥å®ç°
        pass
```

### 3. é«˜çº§å›¾æ¨¡å¼

#### æ‰‡å‡ºæ¨¡å¼ (Fan-out)
```python
# ä¸€ä¸ªèŠ‚ç‚¹è¾“å‡ºåˆ°å¤šä¸ªå¹¶è¡ŒèŠ‚ç‚¹
edges = [
    Edge("start", "branch_a"),
    Edge("start", "branch_b"),
    Edge("start", "branch_c")
]
```

#### æ‰‡å…¥æ¨¡å¼ (Fan-in)
```python
# å¤šä¸ªèŠ‚ç‚¹æ±‡èšåˆ°ä¸€ä¸ªèšåˆèŠ‚ç‚¹
edges = [
    Edge("branch_a", "aggregator"),
    Edge("branch_b", "aggregator"),
    Edge("branch_c", "aggregator")
]
```

#### æ¡ä»¶è¾¹
```python
def condition_function(outputs: dict, state: dict) -> bool:
    return outputs.get("score", 0) > 50

edge = Edge("processor", "next_step", condition=condition_function)
```

#### å¾ªç¯æ¨¡å¼
```python
# è´¨é‡é—¨æ§å¾ªç¯
def quality_gate(inputs: dict) -> dict:
    score = inputs.get("score", 0)
    iteration = inputs.get("iteration", 0)
    
    should_continue = score < 80 and iteration < 3
    return {
        "should_continue": should_continue,
        "iteration": iteration + 1
    }

# æ¡ä»¶è¾¹æ§åˆ¶å¾ªç¯
edge = Edge("quality_gate", "improver", 
           condition=lambda outputs, state: outputs.get("should_continue", False))
```

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€å·¥ä½œæµ
```python
from lite_workflow import Workflow

# åˆ›å»ºç®€å•å·¥ä½œæµ
workflow = Workflow("æ–‡æœ¬å¤„ç†", {"text": "Hello World"})

workflow.add_node("å¤§å†™", lambda x: {"text": x["text"].upper()})
workflow.add_node("åè½¬", lambda x: {"text": x["text"][::-1]})
workflow.add_node("ç»Ÿè®¡", lambda x: {"length": len(x["text"])})

workflow.chain("å¤§å†™", "åè½¬", "ç»Ÿè®¡")

result = workflow.run()
print(result.final_state.to_dict())
```

### å¹¶è¡Œå¤„ç†
```python
from lite_workflow.definitions import Graph, Node, Edge
from lite_workflow.engine import PregelEngine

# åˆ›å»ºå¹¶è¡Œå¤„ç†å›¾
nodes = [
    Node("start", lambda x: {"data": x.get("input", "")}),
    Node("branch_a", lambda x: {"result_a": f"A: {x['data']}"}),
    Node("branch_b", lambda x: {"result_b": f"B: {x['data']}"}),
    Node("aggregate", lambda x: {"final": f"{x.get('result_a', '')} + {x.get('result_b', '')}"})
]

edges = [
    Edge("start", "branch_a"),
    Edge("start", "branch_b"),
    Edge("branch_a", "aggregate"),
    Edge("branch_b", "aggregate")
]

graph = Graph("å¹¶è¡Œå¤„ç†", nodes, edges, "start")
engine = PregelEngine(graph, {"input": "test data"})
result = engine.execute()
```

### LLMé›†æˆå·¥ä½œæµ
```python
from lite_workflow import Workflow
from lite_workflow.components import ChatOpenAI

# åˆ›å»ºLLMå·¥ä½œæµ
workflow = Workflow("AIåŠ©æ‰‹", {"question": "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ"})

def call_llm(inputs: dict) -> dict:
    model = ChatOpenAI(model="gpt-3.5-turbo")
    response = model.invoke(inputs["question"])
    return {"answer": response.content}

def format_response(inputs: dict) -> dict:
    answer = inputs["answer"]
    return {"formatted": f"AIå›ç­”: {answer}"}

workflow.add_node("llm", call_llm)
workflow.add_node("formatter", format_response)
workflow.chain("llm", "formatter")

result = workflow.run()
```

## ğŸ› ï¸ å‘½ä»¤è¡Œä½¿ç”¨

```bash
# è¿è¡Œæ¼”ç¤º
python -m lite_workflow --demo

# è¿è¡Œå·¥ä½œæµæ–‡ä»¶
python -m lite_workflow --workflow path/to/workflow.py

# è¯¦ç»†æ—¥å¿—
python -m lite_workflow --demo --verbose
```

## ğŸ” å…³é”®è®¾è®¡åŸåˆ™

1. **ç±»å‹å®‰å…¨**: å…¨é¢ä½¿ç”¨ç±»å‹æ³¨è§£ï¼Œæ”¯æŒIDEæ™ºèƒ½æç¤º
2. **å¼‚æ­¥ä¼˜å…ˆ**: åŸç”Ÿæ”¯æŒå¼‚æ­¥æ“ä½œï¼Œæé«˜å¹¶å‘æ€§èƒ½
3. **å¯æ‰©å±•æ€§**: æ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºæ·»åŠ æ–°ç»„ä»¶
4. **ä¸­æ–‡å‹å¥½**: é”™è¯¯ä¿¡æ¯å’Œæ—¥å¿—æ”¯æŒä¸­æ–‡
5. **Pregelé£æ ¼**: åŸºäºè¶…æ­¥çš„å›¾è®¡ç®—æ¨¡å¼
6. **LangChainå…¼å®¹**: å·¥å…·ç³»ç»Ÿä¸LangChainé£æ ¼ä¸€è‡´

## ğŸ“š æ‰©å±•å¼€å‘

### è‡ªå®šä¹‰èŠ‚ç‚¹ç±»å‹
```python
class CustomNode(Node):
    def __init__(self, node_id: str, **kwargs):
        super().__init__(node_id, self._execute, **kwargs)
    
    def _execute(self, inputs: dict, **context) -> dict:
        # è‡ªå®šä¹‰æ‰§è¡Œé€»è¾‘
        return {"custom_result": "processed"}
```

### è‡ªå®šä¹‰å·¥å…·
```python
class CustomTool(BaseTool):
    def _run(self, **kwargs) -> str:
        # åŒæ­¥å®ç°
        pass
    
    async def _arun(self, **kwargs) -> str:
        # å¼‚æ­¥å®ç°
        pass
```

### è‡ªå®šä¹‰æ‰§è¡Œå¼•æ“
```python
class CustomEngine(ExecutionEngine):
    async def execute_async(self) -> State:
        # è‡ªå®šä¹‰æ‰§è¡Œé€»è¾‘
        pass
```

è¿™ä¸ªæ¡†æ¶ä¸ºæ„å»ºå¤æ‚çš„AIå·¥ä½œæµæä¾›äº†å¼ºå¤§è€Œçµæ´»çš„åŸºç¡€ï¼Œç‰¹åˆ«é€‚åˆéœ€è¦å¹¶è¡Œå¤„ç†ã€æ¡ä»¶åˆ†æ”¯å’Œè¿­ä»£æ”¹è¿›çš„åœºæ™¯ã€‚ 